#!/usr/bin/env python3
"""
Step-by-Step CTF Scraper Tester
Test each step to see what's working and what's not
"""

import requests
from bs4 import BeautifulSoup

print("=" * 80)
print("üß™ CTF SCRAPER - STEP BY STEP TESTING")
print("=" * 80)

URL = "https://ctf.0xfun.org/challenges"

# ============================================================================
# STEP 1: Test basic connection without any cookies
# ============================================================================
print("\nüìç STEP 1: Testing basic connection (NO cookies)")
print("-" * 80)

try:
    response = requests.get(URL, timeout=10)
    print(f"‚úÖ Status Code: {response.status_code}")
    print(f"‚úÖ Response Length: {len(response.text)} bytes")
    print(f"‚úÖ Content Type: {response.headers.get('content-type', 'N/A')}")
    
    # Check for Cloudflare
    if 'cloudflare' in response.text.lower() or 'Just a moment' in response.text:
        print("‚ö†Ô∏è  CLOUDFLARE DETECTED!")
        print("    The page is showing Cloudflare challenge")
        cloudflare_detected = True
    else:
        cloudflare_detected = False
        print("‚úÖ No Cloudflare challenge detected")
    
    # Check first 500 chars
    print("\nüìÑ First 500 characters of response:")
    print("-" * 80)
    print(response.text[:500])
    print("-" * 80)
    
    # Try to parse as HTML
    soup = BeautifulSoup(response.text, 'lxml')
    title = soup.find('title')
    print(f"\nüìå Page Title: {title.get_text() if title else 'No title found'}")
    
    # Look for challenges
    print("\nüîç Looking for challenge elements...")
    challenges = soup.find_all(['div', 'article'], class_=lambda x: x and 'challenge' in x.lower())
    print(f"   Found {len(challenges)} elements with 'challenge' in class name")
    
except requests.exceptions.RequestException as e:
    print(f"‚ùå Error: {e}")
    cloudflare_detected = False

# ============================================================================
# STEP 2: Test with cookies (if user provides them)
# ============================================================================
print("\n" + "=" * 80)
print("üìç STEP 2: Testing WITH cookies")
print("-" * 80)

cookie_input = input("\nüç™ Paste your cookies here (from document.cookie), or press Enter to skip:\n> ").strip()

if cookie_input:
    print("\nüîÑ Testing with your cookies...")
    
    # Parse cookies
    cookies = {}
    for item in cookie_input.split(';'):
        if '=' in item:
            key, value = item.strip().split('=', 1)
            cookies[key] = value
    
    print(f"üìã Found {len(cookies)} cookies:")
    for key in cookies.keys():
        print(f"   - {key}")
    
    # Make request with cookies
    try:
        response = requests.get(URL, cookies=cookies, timeout=10)
        print(f"\n‚úÖ Status Code: {response.status_code}")
        print(f"‚úÖ Response Length: {len(response.text)} bytes")
        
        # Check for Cloudflare
        if 'cloudflare' in response.text.lower() or 'Just a moment' in response.text:
            print("‚ö†Ô∏è  CLOUDFLARE STILL BLOCKING!")
            print("    Cookies might be incomplete or expired")
        else:
            print("‚úÖ No Cloudflare challenge!")
        
        # Check first 500 chars
        print("\nüìÑ First 500 characters of response:")
        print("-" * 80)
        print(response.text[:500])
        print("-" * 80)
        
        # Parse HTML
        soup = BeautifulSoup(response.text, 'lxml')
        title = soup.find('title')
        print(f"\nüìå Page Title: {title.get_text() if title else 'No title found'}")
        
        # Look for challenges
        print("\nüîç Looking for challenge elements...")
        
        # Try different selectors
        selectors = [
            ('div with "challenge" class', 'div', lambda x: x and 'challenge' in x.lower()),
            ('div with "card" class', 'div', lambda x: x and 'card' in x.lower()),
            ('article tags', 'article', None),
            ('h2, h3, h4 headers', ['h2', 'h3', 'h4'], None),
        ]
        
        for desc, tag, class_filter in selectors:
            if class_filter:
                elements = soup.find_all(tag, class_=class_filter)
            else:
                elements = soup.find_all(tag) if isinstance(tag, str) else soup.find_all(tag)
            
            print(f"   {desc}: {len(elements)} found")
            
            # Show first few
            if elements and len(elements) > 0:
                print(f"      Examples:")
                for elem in elements[:3]:
                    text = elem.get_text(strip=True)[:50]
                    print(f"      - {text}")
        
        # Check if we can find challenge names from your screenshot
        print("\nüéØ Looking for specific challenges from screenshot...")
        keywords = ['TLSB', 'Templates', 'UART', 'Shell', 'Perceptions', 
                   'Leonine', 'Schr√∂dinger', 'Delicious', 'Guess']
        
        for keyword in keywords:
            if keyword.lower() in response.text.lower():
                print(f"   ‚úÖ Found: {keyword}")
            else:
                print(f"   ‚ùå Missing: {keyword}")
        
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Error: {e}")
else:
    print("‚è≠Ô∏è  Skipped cookie test")

# ============================================================================
# STEP 3: Summary and recommendations
# ============================================================================
print("\n" + "=" * 80)
print("üìä SUMMARY")
print("=" * 80)

if cloudflare_detected:
    print("""
‚ö†Ô∏è  CLOUDFLARE IS BLOCKING!

The page is protected by Cloudflare. You MUST:
  1. Open https://ctf.0xfun.org/challenges in browser
  2. Let the page load completely
  3. Press F12 ‚Üí Console tab
  4. Type: document.cookie
  5. Copy ALL output
  6. Run this script again and paste it
    """)
else:
    if cookie_input:
        print("""
‚úÖ SUCCESS! Cookies are working!

Next steps:
  1. Run the full scraper with these cookies
  2. Use the -v flag to see detailed output
        """)
    else:
        print("""
‚ÑπÔ∏è  The page might be accessible without cookies.

But you should still provide cookies to be safe.
Try running STEP 2 with cookies.
        """)

print("=" * 80)
print("\nüí° To run full scraper after testing:")
print("   python ctf_scraper_ultimate.py https://ctf.0xfun.org/challenges \\")
print("     -c \"YOUR_COOKIES\" -v")
print("=" * 80)
